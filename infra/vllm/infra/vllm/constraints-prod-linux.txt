# Linux + NVIDIA CUDA (ex: cu124); keep numpy<2 for vLLM builds
numpy<2.0
torch==2.4.0
transformers>=4.41,<5
pydantic<3
fastapi
uvicorn